{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bullet ArXiv\n",
    " \n",
    "Analysis of astronomy sub-fields with ArXiv paper abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/processed/train.csv')\n",
    "X_val = pd.read_csv('../data/processed/val.csv')\n",
    "X_test = pd.read_csv('../data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from src.abstract import FormatText\n",
    "from src.model import Tokenizer\n",
    "\n",
    "STOP_WORDS = [\n",
    "    \"doi\",\n",
    "    \"preprint\",\n",
    "    \"copyright\",\n",
    "    \"peer\",\n",
    "    \"reviewed\",\n",
    "    \"org\",\n",
    "    \"https\",\n",
    "    \"et\",\n",
    "    \"al\",\n",
    "    \"author\",\n",
    "    \"figure\",\n",
    "    \"rights\",\n",
    "    \"reserved\",\n",
    "    \"permission\",\n",
    "    \"used\",\n",
    "    \"using\",\n",
    "    \"arxiv\",\n",
    "    \"license\",\n",
    "    \"fig\",\n",
    "    \"fig.\",\n",
    "    \"al.\",\n",
    "    \"Elsevier\",\n",
    "    \"PMC\",\n",
    "    \"CZI\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_pipeline(\n",
    "    vectorizer_kwargs, svd_kwargs, kmeans_kwargs, random_state=0\n",
    "):\n",
    "    formatter = FormatText()\n",
    "    vectorizer = TfidfVectorizer(**vectorizer_kwargs)\n",
    "    svd = TruncatedSVD(**svd_kwargs, random_state=random_state)\n",
    "    normalizer = Normalizer()\n",
    "    kmeans = KMeans(**kmeans_kwargs, random_state=random_state)\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"preprocessing\",\n",
    "                Pipeline(\n",
    "                    [\n",
    "                        (\"formatter\", formatter),\n",
    "                        (\"vectorizer\", vectorizer),\n",
    "                        (\"svd\", svd),\n",
    "                        (\"normalizer\", normalizer),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\"kmeans\", kmeans),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def kmeans_distortions(\n",
    "    X,\n",
    "    k_range,\n",
    "    vectorizer_kwargs={},\n",
    "    svd_kwargs={},\n",
    "    kmeans_kwargs={},\n",
    "    **kwargs\n",
    "):\n",
    "    from scipy.spatial.distance import cdist\n",
    "\n",
    "    def distortion(X, estimator):\n",
    "        X_svd = pipeline['preprocessing'].transform(X)\n",
    "        kmeans = estimator['kmeans']\n",
    "        return cdist(X_svd, kmeans.cluster_centers_, \"euclidean\").min(axis=1).sum() / X_svd.shape[0]\n",
    "        \n",
    "    distortions = []\n",
    "    for i, k in enumerate(k_range):\n",
    "        kmeans_kwargs['n_clusters'] = k\n",
    "        pipeline = kmeans_pipeline(\n",
    "            vectorizer_kwargs=vectorizer_kwargs,\n",
    "            svd_kwargs=svd_kwargs,\n",
    "            kmeans_kwargs=kmeans_kwargs,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "        pipeline.fit(X)\n",
    "        distortions.append(distortion(X, pipeline))\n",
    "\n",
    "    return distortions\n",
    "\n",
    "def plot_kmeans_elbow(\n",
    "    X,\n",
    "    k_range,\n",
    "    vectorizer_kwargs={},\n",
    "    svd_kwargs={},\n",
    "    kmeans_kwargs={},\n",
    "    **kwargs\n",
    "):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "    distortions = kmeans_distortions(\n",
    "        X,\n",
    "        k_range,\n",
    "        vectorizer_kwargs=vectorizer_kwargs,\n",
    "        svd_kwargs=svd_kwargs,\n",
    "        kmeans_kwargs=kmeans_kwargs,\n",
    "        **kwargs\n",
    "    )\n",
    "    X_line = [k_range[0], k_range[-1]]\n",
    "    Y_line = [distortions[0], distortions[-1]]\n",
    "\n",
    "    ax.plot(k_range, distortions, \"C0-\")\n",
    "    ax.plot(X_line, Y_line, \"k--\")\n",
    "    ax.set_xlabel(\"k\")\n",
    "    ax.set_ylabel(\"Distortion\")\n",
    "    ax.set_title('KMeans Elbow Plot')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_kmeans_elbow(\n",
    "    X_train,\n",
    "    k_range=range(5, 50, 5),\n",
    "    vectorizer_kwargs={\n",
    "        \"tokenizer\": Tokenizer(user_stopwords=STOP_WORDS, language=\"english\"),\n",
    "        \"max_df\": 0.95,\n",
    "        \"min_df\": 3,\n",
    "        \"ngram_range\": (1, 1),\n",
    "        \"analyzer\": \"word\",\n",
    "    },\n",
    "    svd_kwargs={\"n_components\": 100},\n",
    "    kmeans_kwargs={},\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=1,\n",
    ")\n",
    "fig.savefig('../figures/kmeans_elbow_plot.png', bbox_inches='tight', facecolor='white', edgecolor='none', transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "def tsne_pipeline(\n",
    "    vectorizer_kwargs, svd_kwargs, kmeans_kwargs, tsne_kwargs, random_state=0\n",
    "):\n",
    "    formatter = FormatText()\n",
    "    vectorizer = TfidfVectorizer(**vectorizer_kwargs)\n",
    "    svd = TruncatedSVD(**svd_kwargs, random_state=random_state)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    kmeans = KMeans(**kmeans_kwargs, random_state=random_state)\n",
    "    tsne = TSNE(**tsne_kwargs, random_state=random_state)\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"preprocessing\",\n",
    "                Pipeline(\n",
    "                    [\n",
    "                        (\"formatter\", formatter),\n",
    "                        (\"vectorizer\", vectorizer),\n",
    "                        (\"svd\", svd),\n",
    "                        (\"normalizer\", normalizer),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\"kmeans\", kmeans),\n",
    "            (\"tsne\", tsne)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def plot_tsne_results(X, vectorizer_kwargs, svd_kwargs, kmeans_kwargs, tsne_kwargs, random_state=0):\n",
    "    sns.set(rc={\"figure.figsize\": (13, 9)})\n",
    "\n",
    "    k_clusters = kmeans_kwargs.get(\"n_clusters\")\n",
    "    palette = sns.hls_palette(k_clusters, l=0.4, s=0.9)\n",
    "\n",
    "    pipeline = tsne_pipeline(\n",
    "        vectorizer_kwargs=vectorizer_kwargs,\n",
    "        svd_kwargs=svd_kwargs,\n",
    "        kmeans_kwargs=kmeans_kwargs,\n",
    "        tsne_kwargs=tsne_kwargs,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    X_tsne = pipeline.fit_transform(X)\n",
    "    kmeans_labels = pipeline[\"kmeans\"].predict(pipeline['preprocessing'].transform(X))\n",
    "    axes = sns.scatterplot(\n",
    "        x=X_tsne[:, 0], y=X_tsne[:, 1], hue=kmeans_labels, legend=\"full\", palette=palette\n",
    "    )\n",
    "    plt.title(\"t-SNE with Kmeans Labels\")\n",
    "    return axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = plot_tsne_results(\n",
    "    X_train,\n",
    "    vectorizer_kwargs={\n",
    "        \"tokenizer\": Tokenizer(user_stopwords=STOP_WORDS, language=\"english\"),\n",
    "        \"max_df\": 0.95,\n",
    "        \"min_df\": 3,\n",
    "        \"ngram_range\": (1, 1),\n",
    "        \"analyzer\": \"word\",\n",
    "    },\n",
    "    svd_kwargs={\"n_components\": 100},\n",
    "    kmeans_kwargs={\"n_clusters\": 30},\n",
    "    tsne_kwargs={\"perplexity\": 50, \"init\": \"random\", \"learning_rate\": \"auto\"},\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from src.model import LDACluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_pipeline(\n",
    "    X, n_clusters, user_stopwords, vectorizer_kwargs, lda_kwargs, random_state\n",
    "):\n",
    "    formatter = FormatText()\n",
    "    vectorizer = Vectorizer(\n",
    "        vectorizer=\"counts\",\n",
    "        vectorizer_kwargs=vectorizer_kwargs,\n",
    "        user_stopwords=user_stopwords,\n",
    "    )\n",
    "    lda_cluster = LDACluster(\n",
    "        n_clusters=n_clusters, random_state=random_state, lda_kwargs=lda_kwargs,\n",
    "    )\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"formatter\", formatter),\n",
    "            (\"vectorizer\", vectorizer),\n",
    "            (\"labeller\", lda_cluster),\n",
    "        ]\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def lda_labels(pipeline, words_per_topic):\n",
    "    labels = []\n",
    "    feature_names = pipeline[\"vectorizer\"].vectorizer.get_feature_names_out()\n",
    "    for cluster_labeller in pipeline[\"labeller\"].labellers:\n",
    "        cluster_keywords = []\n",
    "        for ix, topic in enumerate(cluster_labeller.components_):\n",
    "            words = [\n",
    "                feature_names[i] for i in topic.argsort()[: -words_per_topic - 1 : -1]\n",
    "            ]\n",
    "            cluster_keywords.append(words)\n",
    "        labels.append(np.unique(cluster_keywords))\n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_lda_labels(\n",
    "    X,\n",
    "    words_per_topic,\n",
    "    user_stopwords={},\n",
    "    vectorizer_kwargs={},\n",
    "    pca_kwargs={},\n",
    "    kmeans_kwargs={},\n",
    "    lda_kwargs={},\n",
    "    random_state=0,\n",
    "):\n",
    "\n",
    "    n_clusters = kmeans_kwargs.get(\"n_clusters\")\n",
    "    clustering_pipeline = kmeans_pipeline(\n",
    "        user_stopwords=user_stopwords,\n",
    "        vectorizer_kwargs=vectorizer_kwargs,\n",
    "        svd_kwargs=pca_kwargs,\n",
    "        kmeans_kwargs=kmeans_kwargs,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    labelling_pipeline = lda_pipeline(\n",
    "        X,\n",
    "        n_clusters=n_clusters,\n",
    "        user_stopwords=user_stopwords,\n",
    "        vectorizer_kwargs=vectorizer_kwargs,\n",
    "        lda_kwargs=lda_kwargs,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    y = clustering_pipeline.fit_predict(X)\n",
    "    labelling_pipeline.fit(X, y)\n",
    "    return lda_labels(labelling_pipeline, words_per_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_lda_labels(\n",
    "    X_train,\n",
    "    words_per_topic=5,\n",
    "    user_stopwords=STOP_WORDS,\n",
    "    vectorizer_kwargs={\"max_df\": 0.95, \"min_df\": 3, \"ngram_range\": (1, 1)},\n",
    "    pca_kwargs={\"n_components\": 100},\n",
    "    kmeans_kwargs={\"n_clusters\": 20},\n",
    "    lda_kwargs={\"n_components\": 5, \"learning_method\": \"online\"},\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18305810c6a82017c39c49993887778801cd726a3b0d2391bc479abb9cb50551"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
