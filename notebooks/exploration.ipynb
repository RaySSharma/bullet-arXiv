{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/processed/train.csv')\n",
    "X_val = pd.read_csv('../data/processed/val.csv')\n",
    "X_test = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "X = X_train[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = [\n",
    "    \"doi\",\n",
    "    \"preprint\",\n",
    "    \"copyright\",\n",
    "    \"peer\",\n",
    "    \"reviewed\",\n",
    "    \"org\",\n",
    "    \"https\",\n",
    "    \"et\",\n",
    "    \"al\",\n",
    "    \"author\",\n",
    "    \"figure\",\n",
    "    \"rights\",\n",
    "    \"reserved\",\n",
    "    \"permission\",\n",
    "    \"used\",\n",
    "    \"using\",\n",
    "    \"arxiv\",\n",
    "    \"license\",\n",
    "    \"fig\",\n",
    "    \"fig.\",\n",
    "    \"al.\",\n",
    "    \"Elsevier\",\n",
    "    \"PMC\",\n",
    "    \"CZI\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from src.abstract import FormatText\n",
    "from src.model import Vectorizer, SparsePCA, LDACluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_pipeline(\n",
    "    vectorizer_kwargs, user_stopwords, svd_kwargs, kmeans_kwargs, random_state=0\n",
    "):\n",
    "    formatter = FormatText()\n",
    "    vectorizer = Vectorizer(\n",
    "        vectorizer=\"tf-idf\",\n",
    "        vectorizer_kwargs=vectorizer_kwargs,\n",
    "        user_stopwords=user_stopwords,\n",
    "    )\n",
    "    svd = TruncatedSVD(**svd_kwargs, random_state=random_state)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    kmeans = KMeans(**kmeans_kwargs, random_state=random_state)\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"features\",\n",
    "                Pipeline(\n",
    "                    [\n",
    "                        (\"formatter\", formatter),\n",
    "                        (\"vectorizer\", vectorizer),\n",
    "                        (\"svd\", svd),\n",
    "                        (\"normalizer\", normalizer),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\"kmeans\", kmeans),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def optimize_k_clusters(\n",
    "    X, cluster_range, vectorizer_kwargs, svd_kwargs, user_stopwords\n",
    "):\n",
    "    from scipy.spatial.distance import cdist\n",
    "\n",
    "    distortions = []\n",
    "    for n_clusters in cluster_range:\n",
    "        pipeline = kmeans_pipeline(\n",
    "            vectorizer_kwargs=vectorizer_kwargs,\n",
    "            svd_kwargs=svd_kwargs,\n",
    "            kmeans_kwargs={\"n_clusters\": n_clusters},\n",
    "            user_stopwords=user_stopwords,\n",
    "        )\n",
    "        pipeline.fit(X)\n",
    "        X_pca = pipeline[\"features\"].transform(X_train)\n",
    "        distortions.append(\n",
    "            sum(\n",
    "                np.min(\n",
    "                    cdist(X_pca, pipeline[\"kmeans\"].cluster_centers_, \"euclidean\"),\n",
    "                    axis=1,\n",
    "                )\n",
    "            )\n",
    "            / X_pca.shape[0]\n",
    "        )\n",
    "    return distortions\n",
    "\n",
    "\n",
    "def plot_k_cluster_elbow(\n",
    "    X, cluster_range, vectorizer_kwargs={}, svd_kwargs={}, user_stopwords={}\n",
    "):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "    distortions = optimize_k_clusters(\n",
    "        X,\n",
    "        cluster_range,\n",
    "        vectorizer_kwargs=vectorizer_kwargs,\n",
    "        svd_kwargs=svd_kwargs,\n",
    "        user_stopwords=user_stopwords,\n",
    "    )\n",
    "    X_line = [cluster_range[0], cluster_range[-1]]\n",
    "    Y_line = [distortions[0], distortions[-1]]\n",
    "\n",
    "    # Plot the elbow\n",
    "    ax.plot(cluster_range, distortions, \"b-\")\n",
    "    ax.plot(X_line, Y_line, \"r\")\n",
    "    ax.set_xlabel(\"k\")\n",
    "    ax.set_ylabel(\"Distortion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_range = range(2, 30)\n",
    "plot_k_cluster_elbow(\n",
    "    X_train,\n",
    "    cluster_range,\n",
    "    vectorizer_kwargs={\"max_df\": 0.95, \"min_df\": 3, \"ngram_range\": (1, 1),},\n",
    "    svd_kwargs={\"n_components\": 100},\n",
    "    user_stopwords=STOP_WORDS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_pipeline(\n",
    "    user_stopwords={},\n",
    "    vectorizer_kwargs={},\n",
    "    pca_kwargs={},\n",
    "    kmeans_kwargs={},\n",
    "    tsne_kwargs={},\n",
    "    random_state=0,\n",
    "    verbose=0,\n",
    "):\n",
    "    formatter = FormatText()\n",
    "    vectorizer = Vectorizer(\n",
    "        vectorizer_kwargs=vectorizer_kwargs, user_stopwords=user_stopwords\n",
    "    )\n",
    "    pca = SparsePCA(**pca_kwargs, random_state=random_state)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    kmeans = KMeans(**kmeans_kwargs, random_state=random_state)\n",
    "    tsne = TSNE(**tsne_kwargs, verbose=verbose)\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"features\",\n",
    "                Pipeline(\n",
    "                    [\n",
    "                        (\"formatter\", formatter),\n",
    "                        (\"vectorizer\", vectorizer),\n",
    "                        (\"pca\", pca),\n",
    "                        (\"normalizer\", normalizer),\n",
    "                        (\"kmeans\", kmeans),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\"tsne\", tsne),\n",
    "        ]\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def plot_tsne_results(X, user_stopwords={}):\n",
    "    import seaborn as sns\n",
    "    sns.set(rc={\"figure.figsize\": (13, 9)})\n",
    "\n",
    "    palette = sns.hls_palette(20, l=0.4, s=0.9)\n",
    "\n",
    "    pipeline = tsne_pipeline(\n",
    "        user_stopwords=user_stopwords,\n",
    "        vectorizer_kwargs={\"max_df\": 0.95, \"min_df\": 3, \"ngram_range\": (1, 1)},\n",
    "        pca_kwargs={\"n_components\": 100},\n",
    "        kmeans_kwargs={\"n_clusters\": 20},\n",
    "        tsne_kwargs={\"perplexity\": 50, \"init\": \"pca\", \"learning_rate\": \"auto\"},\n",
    "    )\n",
    "\n",
    "    X_tsne = pipeline.fit_transform(X)\n",
    "    hue = pipeline[\"features\"].predict(X)\n",
    "    sns.scatterplot(\n",
    "        x=X_tsne[:, 0], y=X_tsne[:, 1], hue=hue, legend=\"full\", palette=palette\n",
    "    )\n",
    "    plt.title(\"t-SNE with Kmeans Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne_results(X_train, STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_pipeline(\n",
    "    X, n_clusters, user_stopwords, vectorizer_kwargs, lda_kwargs, random_state\n",
    "):\n",
    "    formatter = FormatText()\n",
    "    vectorizer = Vectorizer(\n",
    "        vectorizer=\"counts\",\n",
    "        vectorizer_kwargs=vectorizer_kwargs,\n",
    "        user_stopwords=user_stopwords,\n",
    "    )\n",
    "    lda_cluster = LDACluster(\n",
    "        n_clusters=n_clusters, random_state=random_state, lda_kwargs=lda_kwargs,\n",
    "    )\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"formatter\", formatter),\n",
    "            (\"vectorizer\", vectorizer),\n",
    "            (\"labeller\", lda_cluster),\n",
    "        ]\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def lda_labels(pipeline, words_per_topic):\n",
    "    labels = []\n",
    "    feature_names = pipeline[\"vectorizer\"].vectorizer.get_feature_names_out()\n",
    "    for cluster_labeller in pipeline[\"labeller\"].labellers:\n",
    "        cluster_keywords = []\n",
    "        for ix, topic in enumerate(cluster_labeller.components_):\n",
    "            words = [\n",
    "                feature_names[i] for i in topic.argsort()[: -words_per_topic - 1 : -1]\n",
    "            ]\n",
    "            cluster_keywords.append(words)\n",
    "        labels.append(np.unique(cluster_keywords))\n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_lda_labels(\n",
    "    X,\n",
    "    words_per_topic,\n",
    "    user_stopwords={},\n",
    "    vectorizer_kwargs={},\n",
    "    svd_kwargs={},\n",
    "    kmeans_kwargs={},\n",
    "    lda_kwargs={},\n",
    "    random_state=0,\n",
    "):\n",
    "\n",
    "    n_clusters = kmeans_kwargs.get(\"n_clusters\")\n",
    "    clustering_pipeline = kmeans_pipeline(\n",
    "        user_stopwords=user_stopwords,\n",
    "        vectorizer_kwargs=vectorizer_kwargs,\n",
    "        svd_kwargs=svd_kwargs,\n",
    "        kmeans_kwargs=kmeans_kwargs,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    labelling_pipeline = lda_pipeline(\n",
    "        X,\n",
    "        n_clusters=n_clusters,\n",
    "        user_stopwords=user_stopwords,\n",
    "        vectorizer_kwargs=vectorizer_kwargs,\n",
    "        lda_kwargs=lda_kwargs,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    y = clustering_pipeline.fit_predict(X)\n",
    "    labelling_pipeline.fit(X, y)\n",
    "    return lda_labels(labelling_pipeline, words_per_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_lda_labels(\n",
    "    X_train,\n",
    "    words_per_topic=5,\n",
    "    user_stopwords=STOP_WORDS,\n",
    "    vectorizer_kwargs={\"max_df\": 0.95, \"min_df\": 3, \"ngram_range\": (1, 1)},\n",
    "    svd_kwargs={\"n_components\": 100},\n",
    "    kmeans_kwargs={\"n_clusters\": 20},\n",
    "    lda_kwargs={\"n_components\": 5, \"learning_method\": \"online\"},\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18305810c6a82017c39c49993887778801cd726a3b0d2391bc479abb9cb50551"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
